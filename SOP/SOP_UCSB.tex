\documentclass[12pt]{article}
\setlength{\textwidth}{6.3in}
\setlength{\textheight}{9in}
\setlength{\oddsidemargin}{0in}
\setlength{\evensidemargin}{0in}
\setlength{\topmargin}{-.5in}
%\parindent=0in
\linespread{1.3}
\usepackage{ mathrsfs }
\usepackage{amsthm}
\usepackage{ amssymb }
\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}

\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{fancyhdr}
\pagestyle{fancy}
\headheight = 14.5pt
\lhead{Statement of Purpose - Thomas Zeng}
\rhead{UC Santa Barbara}
\cfoot{\thepage}

\usepackage{tikz}
\usetikzlibrary{positioning}
\begin{document}

%Give a brief statement outlining your reasons for undertaking a graduate program, your particular area of specialization within the major field, your past academic work, and your plans for future occupation or profession. Also include any additional information that may assist the selection committee in evaluating your preparation and aptitude for graduate study at UC Santa Barbara.

Current research has clearly shown the high capacity of deep learning models for generalizing patterns in data. However this comes at a trade off both in the opacity of model predictions and the strong assumption that the data seen at inference time is i.i.d. with respect to the training data. This is especially problematic in domains such as healthcare or policing where explainability and fairness of model predictions is paramount; and furthermore some degree of domain-shift in data at inference time is expected. Hence my current objective is to do research in industry with a focus on finding solutions to this problem, i.e. creating robust, fair and explainable deep learning models.


I developed this goal starting at the end of my sophomore year of college when my interest in the intersection of linguistics and computer science led me to ponder how machine translation algorithms worked. This interest lead me into the field of machine learning.
%To answer this question, I started watching the public online lectures of Stanford's CS244n -- NLP with Deep Learning Course --  which resultingly piqued my interest in the field of AI/ML/DL as a whole. 
I first pursued this interest in industry at a startup, SayKid, that uses pre-built speech recognition models to create interactive talking-robots for children. There I created a voice game premised on riddle solving using the Alexa Skills Kit. This experience underscored to me the necessity of fair and robust models as given the target audience of children, it is necessary that the robot we make follows proper and accurate reasoning process. At the same time, as the APIs I used in this position abstracted away the ML model as a black box that turns pre-defined inputs into pre-defined output, it also made me desire to try research where I could work at a lower level with a greater focus on designing and training models. 
%This experience underscored to me the transformative power of AI through the downstream tasks it makes possible. At the same time, I was not satisfied by working with high-level APIs where the specific architecture of the voice recognition models is abstracted away. Thus I decided to move into research, where I would get to interact closer with DL models.

My first research position was with professor David Lieben-Nowell at my school, who works on understanding human behavior through choice modeling. Here we quantified the effect of geographic location on people's choices -- specifically their ranking of US states by contribution to history. We used a Plackett-Luce model and found that a person's home state's geographic location has a statistically significant affect on their inidividual ranking.
%placket luce
While choice modeling is not machine learning, they have overlaps i.e. they both involve data and modeling -- and through it I gained experience with fundamental ML and data science frameworks. 
Furthermore, I realized that although choice models have low expressitivity in their abilities to approximate functions, they are highly explainable due to the choice theories that underpin them. This is in contrast to DL models that are powerful but black box due to their empirical nature. This juxtaposition again emphasized and propelled me to the problem of robustness and explainability in the context of DL.

 Specifically I participated in a REU program hosted by DePaul University. I was advised by Professor Daniela Raicu and worked on computer aided diagnosis (CAD) classifiers -- to be used by radiologist as an aid in identifying cancerous lung nodules. I focused on improving the domain-shift robustness of these models by identifying hidden stratification in types of lung nodules and training models optimized over these stratifications using group distributionally robust optimization \cite{Sagawa*2020Distributionally}. I also worked on explainability through visualizations of dimensionally reduced features extracted from our DL model. I am the first author on a paper based off this work that will be presented in the SPIE Medical Imaging conference. This program gave me a taste of full-time research and solidified my desire to pursue research through graduate school.
It also again reinforced my interest in explainability and robustness.
 
While my journey into deep learning has not been very long, it has been fruitful and given me a clear direction.
To continue in this direction, I am now doing work on reproducibility and model robustness in NLP with my senior capstone project -- specifically looking at counterfactual fairness in language toxicity classification by re-implementing Counterfactual Logit Pairing \cite{garg2019counterfactual} and evaluating alternative model training methods. I am also holding ML workshops in the data science club at my school to help expose other people to ML in the hopes of bring other people to this field too.

I now desire to get a PhD to further develop my research abilities. While so far, due to the democratized nature of ML, I've been able to learn it by myself without formally taking any ML courses at my school, I believe this is not as much the case for
research which is a fundamentally collaborative effort. Thus I desire to go to a PhD program to further develop my research ability in both finding meaningful questions and also producing useful results.

% %centered on benefits and effects of ai on humans -- human centric research on ai
% I am applying to University of Chicago mainly due to my interest in working with Professor Chenhao Tan in the CHAI lab. His lab's work on human-AI collaboration such as distribution shifts in human-AI decision making \cite{liu2021understanding} and content delegation in content moderation \cite{lai2022human} closely aligns with my own research interests of explainability and robustness. And although, primarily my work with human-AI collaboration has been with CAD algorithms in healthcare, I am excited by the labs focus on NLP as the main ML modality since that is what I am most interested in (and what lead me into ML in the first place).
% But besides the CHAI lab, my previous research was in Chicago and I greatly enjoyed the city. So I believe location wise, it is a good fit for me and would provide me with the right environment to thrive and develop as a researcher.%probably should elaborate more?

% I specifically am applying to University of Minnesota because of its sizeable faculty in machine learning and bioinformatics. I specifically would like to work with Professor Catherine Qi Zhao in the VIP Lab or with Professor Ju Sun in the GLOVEX lab. The former lab is of interest to me due to the work on interpratability and domain shift of models i.e. reasoning capability for attention \cite{chen2021attention}, domain adaptation for training an action recognition classifier \cite{li2017attention} or trustworthiness with steep slope loss \cite{Luo_NeurIPS_2021}. The latter lab is of interest to me due to the focus on healthcare and research in methods to improve classification performance e.g. medical transfer learning \cite{peng2021rethink} and evaluation of COVID-19 detection models \cite{doi:10.1148/ryai.210217}. 
% %need to reword this better
% Besides the faculty, I also enjoy the location of Minneapolis and the cold weather -- and ultimately I think that it can provide the right environment for me to thrive and develop as a researcher.





\bibliographystyle{acm}
\bibliography{refs} % Entries are in the refs.bib file



\end{document}
